{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from dlclive import DLCLive, Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/model'\n",
    "video_path = '/data/videos/video.MOV'\n",
    "frame_path = '/data/frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇에서 보내진 비디오 저장\n",
    "# 이 코드에선 임의로 video_path 이하에 video.MOV로 저장하고 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 프레임 추출\n",
    "vcap = cv2.VideoCapture(video_path)\n",
    "ret, image = vcap.read()\n",
    "\n",
    "cnt = 0\n",
    "width = vcap.get(3)\n",
    "height = vcap.get(4)\n",
    "print(width, height)\n",
    "\n",
    "#WIDTH = 267\n",
    "#HEIGHT = 150\n",
    "RESIZIED_RATIO = 0.3\n",
    "fps = vcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "if os.path.exists(frame_path):\n",
    "    for frame in os.scandir(frame_path):\n",
    "        os.remove(frame.path)\n",
    "\n",
    "while(vcap.isOpened()):\n",
    "    ret, image = vcap.read()\n",
    "    if ret:\n",
    "        #image = cv2.resize(image, dsize=(WIDTH,HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.resize(image, dsize=(0,0), fx=RESIZIED_RATIO, fy=RESIZIED_RATIO, interpolation=cv2.INTER_LINEAR)\n",
    "        #print(vcap.get(1))\n",
    "        if(int(vcap.get(1)) % (int(fps/5)) == 0):\n",
    "            cv2.imwrite(frame_path + '/frame%d.png' % cnt, image)\n",
    "            #cv2.imshow('frame', image)\n",
    "            #print('/content/gdrive/MyDrive/data/frames/frame%d.png' % cnt +'save succeed')\n",
    "            cnt += 1\n",
    "    else:\n",
    "        print('All the frames are read!')\n",
    "        break\n",
    "vcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = int(width * RESIZIED_RATIO)\n",
    "height = int(height * RESIZIED_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출된 모든 프레임에 대해 keypoint detection\n",
    "\n",
    "total_points = []\n",
    "for i in range(cnt):\n",
    "    video_points = []\n",
    "    img = cv2.imread(frame_path + '/frame%d.png'%(i))\n",
    "    #img = cv2.imread(frame)\n",
    "    dlc_proc = Processor()\n",
    "    dlc_live = DLCLive(model_path, processor=dlc_proc)\n",
    "    dlc_live.init_inference(img)\n",
    "    points = dlc_live.get_pose(img)\n",
    "    for i in points:\n",
    "        video_points.append(i[0]/width)\n",
    "        video_points.append(i[1]/height)\n",
    "    total_points.append(video_points)\n",
    "\n",
    "FRAME_LENGTH = 100\n",
    "NUMBER_OF_POINTS = 30\n",
    "if len(total_points) >= FRAME_LENGTH:\n",
    "    total_points = total_points[:FRAME_LENGTH] \n",
    "else:\n",
    "    for i in range(FRAME_LENGTH - len(total_points)):\n",
    "        total_points.append([0 for i in range(NUMBER_OF_POINTS)])\n",
    "\n",
    "total_points = np.array(total_points)\n",
    "#total_points.shape # (100,30)\n",
    "total_points = np.reshape(total_points, ((1,) + total_points.shape)) # (1,100,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict emotion by LSTM model\n",
    "from tensorflow.keras.models import load_model\n",
    "trained_lstm_model = load_model(model_path + '/best_model.h5')\n",
    "prediction = trained_lstm_model.predict(total_points)\n",
    "predicted_emotion = np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predicted_emotion == 0:\n",
    "    y = '공격성'\n",
    "elif predicted_emotion == 1:\n",
    "    y = '공포'\n",
    "elif predicted_emotion == 2:\n",
    "    y = '불안/슬픔'\n",
    "elif predicted_emotion == 3:\n",
    "    y = '편안/안정'\n",
    "elif predicted_emotion == 4:\n",
    "    y = '행복/즐거움'\n",
    "else:\n",
    "    y = '화남/불쾌'\n",
    "\n",
    "print(y) # y: 분석결과 감정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
