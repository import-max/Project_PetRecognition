{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb71c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c03e739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './Training/DOG/train_jsons'\n",
    "valid_path = './Validation/DOG/valid_jsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1e82189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Training/DOG/train_jsons\\\\BODYLOWER', './Training/DOG/train_jsons\\\\BODYSCRATCH', './Training/DOG/train_jsons\\\\BODYSHAKE', './Training/DOG/train_jsons\\\\FEETUP', './Training/DOG/train_jsons\\\\FOOTUP', './Training/DOG/train_jsons\\\\HEADING', './Training/DOG/train_jsons\\\\LYING', './Training/DOG/train_jsons\\\\MOUNTING', './Training/DOG/train_jsons\\\\SIT', './Training/DOG/train_jsons\\\\TAILING', './Training/DOG/train_jsons\\\\TAILLOW', './Training/DOG/train_jsons\\\\TURN', './Training/DOG/train_jsons\\\\WALKRUN']\n"
     ]
    }
   ],
   "source": [
    "train_file_list = glob.glob(train_path + '/*')\n",
    "print(train_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ef9a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39537\n"
     ]
    }
   ],
   "source": [
    "# 총 train dataset video 갯수\n",
    "sum = 0\n",
    "for path in train_file_list:\n",
    "    train_json_list = glob.glob(path + '/*')\n",
    "    sum += len(train_json_list)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "772dede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4949\n"
     ]
    }
   ],
   "source": [
    "# 총 valid dataset video 갯수\n",
    "sum = 0\n",
    "valid_file_list = glob.glob(valid_path + '/*')\n",
    "for path in valid_file_list:\n",
    "    valid_json_list = glob.glob(path + '/*')\n",
    "    sum += len(valid_json_list)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34c5c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(file_path, FRAME_LENGTH=100, NUMBER_OF_POINTS=30):\n",
    "    file_list = glob.glob(file_path + '/*')\n",
    "    total_X = []\n",
    "    total_labels = []\n",
    "    \n",
    "    for path in file_list:\n",
    "        json_list = glob.glob(path + '/*')\n",
    "        for jsonname in json_list:\n",
    "            with open(jsonname, 'r', encoding='UTF-8') as json_file:\n",
    "                video_kp_list = []\n",
    "                json_data = json.load(json_file)\n",
    "                height = json_data[\"metadata\"][\"height\"]\n",
    "                width = json_data[\"metadata\"][\"width\"]\n",
    "                emotion = json_data[\"metadata\"]['inspect']['emotion']\n",
    "                total_labels.append(emotion)\n",
    "                \n",
    "                for item in json_data[\"annotations\"]:\n",
    "                    frame_kp_list = []\n",
    "                    for key, value in sorted(item['keypoints'].items(), key=lambda item: int(item[0])):\n",
    "                        if value is not None:\n",
    "                            frame_kp_list.append(value['x']/width)\n",
    "                            frame_kp_list.append(value['y']/height)\n",
    "                        else:\n",
    "                            frame_kp_list.append(0)\n",
    "                            frame_kp_list.append(0)\n",
    "                    video_kp_list.append(frame_kp_list) \n",
    "                \n",
    "                # 프레임 수 패딩(길이: 100)\n",
    "                FRAME_LENGTH = 100\n",
    "                NUMBER_OF_POINTS = 30\n",
    "                if len(video_kp_list) >= FRAME_LENGTH:\n",
    "                    video_kp_list = video_kp_list[:FRAME_LENGTH] \n",
    "                else:\n",
    "                    for i in range(FRAME_LENGTH - len(video_kp_list)):\n",
    "                        video_kp_list.append([0 for i in range(NUMBER_OF_POINTS)])\n",
    "                        \n",
    "                total_X.append(video_kp_list)\n",
    "        \n",
    "    total_X = np.array(total_X)\n",
    "    total_Y = np.array(total_labels)\n",
    "    return total_X, total_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2a07feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39537, 100, 30) (39537,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y = getDataset(file_path=train_path)\n",
    "print(train_X.shape, train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d8025d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.42638889 0.3828125  0.44861111 ... 0.         0.76111111 0.57265625]\n",
      "  [0.41388889 0.4109375  0.42638889 ... 0.         0.77361111 0.58515625]\n",
      "  [0.3875     0.4078125  0.41388889 ... 0.         0.7875     0.57265625]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.4015625  ... 0.99444444 0.41822917 0.75740741]\n",
      "  [0.         0.         0.36614583 ... 0.97962963 0.365625   0.77685185]\n",
      "  [0.         0.         0.30260417 ... 0.         0.4203125  0.84814815]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[5:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e40b2c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['편안/안정' '편안/안정' '편안/안정']\n"
     ]
    }
   ],
   "source": [
    "print(train_Y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ca0ce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4949, 100, 30) (4949,)\n"
     ]
    }
   ],
   "source": [
    "valid_X, valid_Y = getDataset(file_path=valid_path)\n",
    "print(valid_X.shape, valid_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6363945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5125     0.67890625 0.54583333 ... 0.25859375 0.56666667 0.203125  ]\n",
      " [0.525      0.67578125 0.55416667 ... 0.2609375  0.46666667 0.1828125 ]\n",
      " [0.53194444 0.6828125  0.55694444 ... 0.2796875  0.29444444 0.178125  ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]] 불안/슬픔\n"
     ]
    }
   ],
   "source": [
    "print(valid_X[0], valid_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3e49ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset numpy array\n",
    "np.savez('train_dataset.npz', X=train_X, Y=train_Y)\n",
    "np.savez('valid_dataset.npz', X=valid_X, Y=valid_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a63f814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "Y\n"
     ]
    }
   ],
   "source": [
    "# load npz\n",
    "data = np.load('train_dataset.npz')\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98af8f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45277778, 0.45546875, 0.46805556, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.45277778, 0.45546875, 0.46805556, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.45138889, 0.4609375 , 0.46805556, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b585fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39537, 100, 30) (39537,)\n"
     ]
    }
   ],
   "source": [
    "test1 = data['X']\n",
    "test2 = data['Y']\n",
    "print(test1.shape, test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "786050c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39537, 100, 30)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b89076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
